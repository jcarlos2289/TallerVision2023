{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49cef52e-add4-468d-a5b1-a36a568d793e",
   "metadata": {},
   "source": [
    "# Filtros, Cartonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e4a93e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb1f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartoonize(rgb_image: np.ndarray, num_pyr_downs=2, num_bilaterals=7):\n",
    "    # STEP 1 -- Apply a bilateral filter to reduce the color palette of\n",
    "    # the image.\n",
    "    downsampled_img = rgb_image\n",
    "    for _ in range(num_pyr_downs):\n",
    "        downsampled_img = cv2.pyrDown(downsampled_img)\n",
    "\n",
    "    for _ in range(num_bilaterals):\n",
    "        filterd_small_img = cv2.bilateralFilter(downsampled_img, 9, 9, 7)\n",
    "\n",
    "    filtered_normal_img = filterd_small_img\n",
    "    for _ in range(num_pyr_downs):\n",
    "        filtered_normal_img = cv2.pyrUp(filtered_normal_img)\n",
    "\n",
    "    # make sure resulting image has the same dims as original\n",
    "    if filtered_normal_img.shape != rgb_image.shape:\n",
    "        filtered_normal_img = cv2.resize(\n",
    "            filtered_normal_img, rgb_image.shape[:2])\n",
    "\n",
    "    # STEP 2 -- Convert the original color image into grayscale.\n",
    "    img_gray = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)\n",
    "    # STEP 3 -- Apply a median blur to reduce image noise.\n",
    "    img_blur = cv2.medianBlur(img_gray, 7)\n",
    "\n",
    "    # STEP 4 -- Use adaptive thresholding to detect and emphasize the edges\n",
    "    # in an edge mask.\n",
    "    gray_edges = cv2.adaptiveThreshold(img_blur, 255,\n",
    "                                       cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                       cv2.THRESH_BINARY, 9, 2)\n",
    "    # STEP 5 -- Combine the color image from step 1 with the edge mask\n",
    "    # from step 4.\n",
    "    rgb_edges = cv2.cvtColor(gray_edges, cv2.COLOR_GRAY2RGB)\n",
    "    cartoon_image = cv2.bitwise_and(filtered_normal_img, rgb_edges)\n",
    "   \n",
    "                   \n",
    "    return cartoon_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a42539b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_CAP_PROP_FRAME_WIDTH: '640.0'\n",
      "CV_CAP_PROP_FRAME_HEIGHT : '480.0'\n",
      "CAP_PROP_FPS : '30.0'\n"
     ]
    }
   ],
   "source": [
    "# Definir la camara a utilizar\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Obtener ciertas propiedades del dispositivo de captura (frame width, frame height y frames per second (fps)):\n",
    "frame_width = capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "frame_height = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Imprimir estos valores\n",
    "print(\"CV_CAP_PROP_FRAME_WIDTH: '{}'\".format(frame_width))\n",
    "print(\"CV_CAP_PROP_FRAME_HEIGHT : '{}'\".format(frame_height))\n",
    "print(\"CAP_PROP_FPS : '{}'\".format(fps))\n",
    "\n",
    "# Verificar si la camara se abrio adecuadamente\n",
    "if capture.isOpened() is False:\n",
    "    print(\"Error al abrir la camara\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39193806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contador para guardar las imágenes\n",
    "frame_index = 0\n",
    "factor = 1\n",
    "# Leer hasta que se completen las acciones\n",
    "while capture.isOpened():\n",
    "    # Capturar frame-by-frame la información de la camara\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    if ret is True:\n",
    "        # Mostrar el frame capturado\n",
    "        \n",
    "        # Nuevo Tamaño\n",
    "        h,w,c  = frame.shape\n",
    "        # resize image\n",
    "        #frame = cv2.resize(frame, (int(w*factor), int(h*factor)))\n",
    "             \n",
    "        imgCartoon = cartoonize(frame)\n",
    "        cv2.imshow('Resultado', imgCartoon)\n",
    "        \n",
    "        \n",
    "        # Presionar C para guardar\n",
    "        if cv2.waitKey(20) & 0xFF == ord('c'):\n",
    "            frame_name = \"out/camera_frame_{}.png\".format(frame_index)\n",
    "            cv2.imwrite(frame_name, imgCartoon)\n",
    "            \n",
    "            frame_index += 1\n",
    "\n",
    "        # Presionar q para salir\n",
    "        if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "            break\n",
    "    # Romper el bucle\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Liberar camara y limpiar ventanas\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78c758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "5dd0c637c1fb96891f1f93a246e95f6870710426daa6c226647e2a91f745d134"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
